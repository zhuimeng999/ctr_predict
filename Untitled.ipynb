{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', 'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'weekday']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rnn_layers = 3\n",
    "\n",
    "with open('output/train_preprocessed.csv', 'r') as f:\n",
    "    columns = f.readline().strip().split(',')\n",
    "\n",
    "with open('output/feature_dict.pickle', 'rb') as f:\n",
    "    feature_dict = pickle.load(f)\n",
    "\n",
    "print('columns:', columns)\n",
    "\n",
    "x_len = len(columns) - 2\n",
    "\n",
    "x = tf.placeholder(dtype=tf.int32, shape=(batch_size, x_len))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(batch_size, 1))\n",
    "\n",
    "x_embed = []\n",
    "\n",
    "embeddings_list=[]\n",
    "\n",
    "with tf.name_scope('embeddings'):\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([24, 3], -1.0, 1.0))\n",
    "    embeddings_list.append(embeddings)\n",
    "    embed = tf.nn.embedding_lookup(embeddings, x[:, 0])\n",
    "    x_embed.append(embed)\n",
    "\n",
    "for i in range(2, len(columns) - 1):\n",
    "    with tf.name_scope('embeddings'):\n",
    "        feature_size = len(feature_dict[columns[i]])\n",
    "        embeddings = tf.Variable(\n",
    "            tf.random_uniform([feature_size, 3], -1.0, 1.0))\n",
    "        embeddings_list.append(embeddings)\n",
    "        embed = tf.nn.embedding_lookup(embeddings, x[:, i - 1])\n",
    "        x_embed.append(embed)\n",
    "\n",
    "with tf.name_scope('embeddings'):\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([7, 3], -1.0, 1.0))\n",
    "    embeddings_list.append(embeddings)\n",
    "    embed = tf.nn.embedding_lookup(embeddings, x[:, x_len - 1])\n",
    "    x_embed.append(embed)\n",
    "\n",
    "x_embed = tf.concat(x_embed, 1)\n",
    "x_embed_size = x_embed.shape.as_list()\n",
    "w1 = tf.get_variable('w1', initializer=tf.truncated_normal((x_embed_size[1], x_embed_size[1])))\n",
    "b1 = tf.get_variable('b1', initializer=tf.truncated_normal((1, x_embed_size[1])))\n",
    "logists1 = tf.matmul(x_embed, w1) + b1\n",
    "activate1 = tf.nn.tanh(logists1)\n",
    "\n",
    "w2 = tf.get_variable('w2', initializer=tf.truncated_normal((x_embed_size[1], 1)))\n",
    "b2 = tf.get_variable('b2', initializer=tf.truncated_normal((1, 1)))\n",
    "logists2 = tf.matmul(activate1, w2) + b2\n",
    "y_ = tf.nn.sigmoid(logists2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.log_loss(y, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'log_loss/value:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  1  1]\n",
      " [ 0  0  0 ...  1  1  1]\n",
      " [ 0  0  0 ...  1  1  1]\n",
      " ...\n",
      " [ 0  0  0 ...  6 15  1]\n",
      " [ 0  0  0 ...  2  6  1]\n",
      " [ 0  1  0 ...  0 15  1]]\n"
     ]
    }
   ],
   "source": [
    "with open('output/train_preprocessed.csv', 'r') as f:\n",
    "    f.readline()\n",
    "    k = 0\n",
    "    lines = []\n",
    "    for line in f:\n",
    "        k += 1\n",
    "        lines.append(list(map(lambda x: int(x), line.strip().split(',')[2:])))\n",
    "        if k == batch_size:\n",
    "            print(np.asarray(lines))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  1,  1],\n",
       "       [ 0,  0,  0, ...,  1,  1,  1],\n",
       "       [ 0,  0,  0, ...,  1,  1,  1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  6, 15,  1],\n",
       "       [ 0,  0,  0, ...,  2,  6,  1],\n",
       "       [ 0,  1,  0, ...,  0, 15,  1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 617971, 12, 0, 0, 13, 0, 0, 0, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
